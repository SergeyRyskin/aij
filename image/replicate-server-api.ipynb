{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXa9IwkeokWH"
      },
      "source": [
        "# Getting Started with Replicate\n",
        "This notebook shows how to run models on [Replicate](https://replicate.com).\n",
        "\n",
        "Last updated: 2023-04-24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "0rJP51rc6p3r"
      },
      "source": [
        ">[Run a model from Python](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=UXa9IwkeokWH)\n",
        "\n",
        ">[Setup](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=ep0A2pLDnoWK)\n",
        "\n",
        ">[Run a model](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=Ax6xbVZOpnaV)\n",
        "\n",
        ">[Run a model in the background](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=xLvskaxwtswn)\n",
        "\n",
        ">[Run a model in the background and get a webhook](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=X7ZZHjNrunwr)\n",
        "\n",
        ">[Compose models into a pipeline](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=xyfeLTILu3ad)\n",
        "\n",
        ">[Get streaming output from a running model](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=WM47DByLrk5l)\n",
        "\n",
        ">[Cancel a prediction](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=K7kZwHzLwWoM)\n",
        "\n",
        ">[Load output files](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=5cuMDPg1xjQZ)\n",
        "\n",
        ">[Next steps](#updateTitle=true&folderId=18DKj1jLZ00WQAwMRuIYM22n5yGpZzb1r&scrollTo=vz6FASGXsefP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep0A2pLDnoWK"
      },
      "source": [
        "# Setup\n",
        "\n",
        "To run this notebook, you’ll need to create a [Replicate](https://replicate.com) account and install the Replicate python client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLTW6u8LnkDg",
        "outputId": "a96a7e58-c281-4362-c60a-701dc87982b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: replicate in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (0.8.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from replicate) (23.1)\n",
            "Requirement already satisfied: requests>2 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from replicate) (2.28.2)\n",
            "Requirement already satisfied: pydantic>1 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from replicate) (1.10.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from pydantic>1->replicate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from requests>2->replicate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from requests>2->replicate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from requests>2->replicate) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yilma\\.virtualenvs\\aij-l0atph4u\\lib\\site-packages (from requests>2->replicate) (3.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# install replicate client\n",
        "%pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZTkrAUhoIJE",
        "outputId": "f86196ed-5164-4415-b1ae-c1ccec72a95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "# get a token: https://replicate.com/account\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax6xbVZOpnaV"
      },
      "source": [
        "# Run a model\n",
        "You can run any public model on Replicate from your Python code. The following example runs [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQCcYU6_nXub",
        "outputId": "9f900a7e-9696-4623-f9b7-2ec5873cbc2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['https://replicate.delivery/pbxt/nxwH1b1dvH6iI1Sk71HzlTq4pw4TiQEc5Qfn0nWedVqzhC2QA/out-0.png']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import replicate \n",
        "\n",
        "output = replicate.run(\n",
        "  \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
        "  input={\"prompt\": \"a programmer in a dark room with a computer and a cup of coffee\"}\n",
        ")\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "l2sNBQg-pywR",
        "outputId": "259e924a-1929-4736-d703-f3cb398aaa24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/nxwH1b1dvH6iI1Sk71HzlTq4pw4TiQEc5Qfn0nWedVqzhC2QA/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(url=output[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUZBwKOYqozu"
      },
      "source": [
        "Some models receive images as inputs. To pass a file as an input, use a file handle or URL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NaQ3Jytoqyk5",
        "outputId": "d02626a1-cde4-4e24-ef1f-d1cf80621507"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'a man working on a laptop'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# image = open(\"mystery.jpg\", \"rb\")\n",
        "# or...\n",
        "# image = \"https://example.com/mystery.jpg\"\n",
        "#\n",
        "# for this example, let's use the URL from the previous prediction:\n",
        "image = output[0]\n",
        "\n",
        "replicate.run(\n",
        "  \"andreasjansson/blip-2:4b32258c42e9efd4288bb9910bc532a69727f9acd26aa08e175713a0a857a608\",\n",
        "  input={\"image\": output[0], \"prompt\": \"what's in this picture?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLvskaxwtswn"
      },
      "source": [
        "# Run a model in the background\n",
        "You can start a model and run it in the background:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v0SlZt3Otx6Q"
      },
      "outputs": [],
      "source": [
        "model = replicate.models.get(\"stability-ai/stablelm-tuned-alpha-7b\")\n",
        "version = model.versions.get(\"c49dae362cbaecd2ceabb5bd34fdb68413c4ff775111fea065d259d577757beb\")\n",
        "\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"How do you make ratatouille?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIA6_2auuFe2",
        "outputId": "d97c465c-3394-4460-bd54-a9c25e36886b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(id='gm56uclhfne4plwyk7nwlmx5pi', error=None, input={'prompt': 'How do you make ratatouille?'}, logs=None, output=None, status='starting', version=Version(id='c49dae362cbaecd2ceabb5bd34fdb68413c4ff775111fea065d259d577757beb', created_at=datetime.datetime(2023, 4, 20, 23, 7, 42, 348263, tzinfo=datetime.timezone.utc), cog_version='0.7.0-beta17', openapi_schema={'info': {'title': 'Cog', 'version': '0.1.0'}, 'paths': {'/': {'get': {'summary': 'Root', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Root  Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'root__get'}}, '/shutdown': {'post': {'summary': 'Start Shutdown', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Start Shutdown Shutdown Post'}}}, 'description': 'Successful Response'}}, 'operationId': 'start_shutdown_shutdown_post'}}, '/predictions': {'post': {'summary': 'Predict', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model', 'operationId': 'predict_predictions_post', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionRequest'}}}}}}, '/health-check': {'get': {'summary': 'Healthcheck', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Healthcheck Health Check Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'healthcheck_health_check_get'}}, '/predictions/{prediction_id}': {'put': {'summary': 'Predict Idempotent', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}, {'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model (idempotent creation).', 'operationId': 'predict_idempotent_predictions__prediction_id__put', 'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/PredictionRequest'}], 'title': 'Prediction Request'}}}, 'required': True}}}, '/predictions/{prediction_id}/cancel': {'post': {'summary': 'Cancel', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Cancel Predictions  Prediction Id  Cancel Post'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}], 'description': 'Cancel a running prediction', 'operationId': 'cancel_predictions__prediction_id__cancel_post'}}}, 'openapi': '3.0.2', 'components': {'schemas': {'Input': {'type': 'object', 'title': 'Input', 'properties': {'top_p': {'type': 'number', 'title': 'Top P', 'default': 1, 'maximum': 1, 'minimum': 0.01, 'x-order': 2, 'description': 'Valid if you choose top_p decoding. When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens'}, 'prompt': {'type': 'string', 'title': 'Prompt', 'default': \"What's your mood today?\", 'x-order': 0, 'description': 'Input Prompt.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'default': 100, 'minimum': 1, 'x-order': 1, 'description': 'Maximum number of tokens to generate. A word is generally 2-3 tokens'}, 'temperature': {'type': 'number', 'title': 'Temperature', 'default': 0.75, 'maximum': 5, 'minimum': 0.01, 'x-order': 3, 'description': 'Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic, 0.75 is a good starting value.'}, 'repetition_penalty': {'type': 'number', 'title': 'Repetition Penalty', 'default': 1.2, 'maximum': 5, 'minimum': 0.01, 'x-order': 4, 'description': 'Penalty for repeated words in generated text; 1 is no penalty, values greater than 1 discourage repetition, less than 1 encourage it.'}}}, 'Output': {'type': 'array', 'items': {'type': 'string'}, 'title': 'Output', 'x-cog-array-type': 'iterator', 'x-cog-array-display': 'concatenate'}, 'Status': {'enum': ['starting', 'processing', 'succeeded', 'canceled', 'failed'], 'type': 'string', 'title': 'Status', 'description': 'An enumeration.'}, 'WebhookEvent': {'enum': ['start', 'output', 'logs', 'completed'], 'type': 'string', 'title': 'WebhookEvent', 'description': 'An enumeration.'}, 'ValidationError': {'type': 'object', 'title': 'ValidationError', 'required': ['loc', 'msg', 'type'], 'properties': {'loc': {'type': 'array', 'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}]}, 'title': 'Location'}, 'msg': {'type': 'string', 'title': 'Message'}, 'type': {'type': 'string', 'title': 'Error Type'}}}, 'PredictionRequest': {'type': 'object', 'title': 'PredictionRequest', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'input': {'$ref': '#/components/schemas/Input'}, 'webhook': {'type': 'string', 'title': 'Webhook', 'format': 'uri', 'maxLength': 65536, 'minLength': 1}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'output_file_prefix': {'type': 'string', 'title': 'Output File Prefix'}, 'webhook_events_filter': {'type': 'array', 'items': {'$ref': '#/components/schemas/WebhookEvent'}, 'default': ['output', 'logs', 'completed', 'start'], 'uniqueItems': True}}}, 'PredictionResponse': {'type': 'object', 'title': 'PredictionResponse', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'logs': {'type': 'string', 'title': 'Logs', 'default': ''}, 'error': {'type': 'string', 'title': 'Error'}, 'input': {'$ref': '#/components/schemas/Input'}, 'output': {'$ref': '#/components/schemas/Output'}, 'status': {'$ref': '#/components/schemas/Status'}, 'metrics': {'type': 'object', 'title': 'Metrics'}, 'version': {'type': 'string', 'title': 'Version'}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'started_at': {'type': 'string', 'title': 'Started At', 'format': 'date-time'}, 'completed_at': {'type': 'string', 'title': 'Completed At', 'format': 'date-time'}}}, 'HTTPValidationError': {'type': 'object', 'title': 'HTTPValidationError', 'properties': {'detail': {'type': 'array', 'items': {'$ref': '#/components/schemas/ValidationError'}, 'title': 'Detail'}}}}}}), started_at=None, created_at='2023-04-27T06:01:00.630251Z', completed_at=None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJ5Mll-JuPXl",
        "outputId": "baac8390-52ea-4dc9-ee48-3a055e613ab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'starting'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owP4pydEuQ-A",
        "outputId": "772f641f-6673-4eaa-da15-b3fd5acc0bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['id', 'error', 'input', 'logs', 'output', 'status', 'version', 'started_at', 'created_at', 'completed_at'])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(prediction).keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q6rKX8e7uXRd"
      },
      "outputs": [],
      "source": [
        "prediction.reload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eLma8KgJuZ9t",
        "outputId": "1a8edd8b-2987-434b-8f26-683901835962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'succeeded'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DIdTadrBujYZ",
        "outputId": "881f6468-0590-437e-bca0-44188801d998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There’s quite a lot of debate about how best to prepare this dish - I think there are two main ways to cook it: with a “traditional” method using the ramps or eggplant; then for something quicker and easier, cooking your petals on top can work well too! What we chose here was inspired by my friend Pierre Franey who made his own traditional recipe from scratch...'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''.join(prediction.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ZZHjNrunwr"
      },
      "source": [
        "# Run a model in the background and get a webhook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y264GRLRuyW2"
      },
      "source": [
        "You can run a model and get a webhook when it completes, instead of waiting for it to finish. \n",
        "\n",
        "If you're working locally, we'd recommend using [ngrok](https://ngrok.com/download) for debugging webhooks. It allows you to tunnel your localhost to a public domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7iH_9-Lum69"
      },
      "outputs": [],
      "source": [
        "model = replicate.models.get(\"kvfrans/clipdraw\")\n",
        "version = model.versions.get(\"5797a99edc939ea0e9242d5e8c9cb3bc7d125b1eac21bda852e5cb79ede2cd9b\")\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"Watercolor painting of an underwater submarine\"},\n",
        "    webhook=\"https://example.com/your-webhook\",\n",
        "    webhook_events_filter=[\"completed\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyfeLTILu3ad"
      },
      "source": [
        "# Compose models into a pipeline\n",
        "You can run a model and feed the output into another model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9VNlqEtu-X5"
      },
      "outputs": [],
      "source": [
        "# laionide = replicate.models.get(\"afiaka87/laionide-v4\").versions.get(\"b21cbe271e65c1718f2999b038c18b45e21e4fba961181fbfae9342fc53b9e05\")\n",
        "# swinir = replicate.models.get(\"jingyunliang/swinir\").versions.get(\"660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a\")\n",
        "# image = laionide.predict(prompt=\"avocado armchair\")\n",
        "# upscaled_image = swinir.predict(image=image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXqf8OmTu-EG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM47DByLrk5l"
      },
      "source": [
        "# Get streaming output from a running model\n",
        "Some models stream output as the model is running. They will return an iterator, and you can iterate over that output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkjJKac8rlS2",
        "outputId": "ab07ed31-8d04-4710-8b4b-47222bcec419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dolly\n",
            " was\n",
            " a\n",
            " sheep\n",
            " who\n",
            " was\n",
            " the\n",
            " first\n",
            " successfully\n",
            " cloned\n",
            " mammal\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "iterator = replicate.run(\n",
        "  \"replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5\",\n",
        "  input={\"prompt\": \"Who was Dolly the sheep?\"},\n",
        ")\n",
        "for text in iterator:\n",
        "      print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7kZwHzLwWoM"
      },
      "source": [
        "# Cancel a prediction\n",
        "You can cancel a running prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YryIQVJ7wWHt"
      },
      "outputs": [],
      "source": [
        "model = replicate.models.get(\"cjwbw/damo-text-to-video\")\n",
        "version = model.versions.get(\"1e205ea73084bd17a0a3b43396e49ba0d6bc2e754e9283b2df49fad2dcf95755\")\n",
        "\n",
        "prediction = replicate.predictions.create(\n",
        "    version=version,\n",
        "    input={\"prompt\":\"How do you make ratatouille?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zwVtyEVLw4o_",
        "outputId": "53c09862-56f7-4be3-9ad2-e819e689ab2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'starting'"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BME9JCeNw5qe"
      },
      "outputs": [],
      "source": [
        "prediction.cancel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inuDz8Dtw6ox"
      },
      "outputs": [],
      "source": [
        "prediction.reload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NRZbHkXNw8jJ",
        "outputId": "aaf507ee-eb01-4f4f-9429-cf4c25867c4c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'canceled'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PV0EnN4xFf5",
        "outputId": "fd630777-a4ef-4aa2-985a-ba304ea482b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['starting', 'succeeded', 'succeeded', 'succeeded', 'succeeded']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = replicate.predictions.list()\n",
        "\n",
        "[p.status for p in predictions[:10]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cuMDPg1xjQZ"
      },
      "source": [
        "# Load output files\n",
        "Output files are returned as HTTPS URLs. You can load an output file as a buffer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTcA8OGYxmCe",
        "outputId": "bc5336ae-098d-42ec-9e12-b5f4f2cf483c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/tmp/out.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m version \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mversions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m out \u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mpredict(prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwavy colorful abstract patterns, cgsociety\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m urlretrieve(out[\u001b[39m0\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39m/tmp/out.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32m~\\OneDrive\\Apps\\Local\\apps\\anaconda3\\2023.03\\lib\\urllib\\request.py:251\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39m# Handle temporary file setup.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m--> 251\u001b[0m     tfp \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tfp \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mNamedTemporaryFile(delete\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/out.png'"
          ]
        }
      ],
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "model = replicate.models.get(\"stability-ai/stable-diffusion\")\n",
        "version = model.versions.get(\"27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\")\n",
        "out = version.predict(prompt=\"wavy colorful abstract patterns, cgsociety\")\n",
        "urlretrieve(out[0], \"/tmp/out.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz6FASGXsefP"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "- Explore our collection of hosted [models](https://replicate.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "- Learn about how to integrate with [LangChain](https://python.langchain.com/en/latest/modules/models/llms/integrations/replicate.html)\n",
        "\n",
        "\n",
        "\n",
        "- Note that you can also run models with the raw HTTP API. Refer to the [HTTP API reference](https://replicate.com/docs/reference/http) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzRipDfdyu_D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
